{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This script will import and parse the entire SMILES database from the COD.\n",
    "\n",
    "Those SMILES will then be compared to a testing set from OpenFF to define a test set\n",
    "of CIF files (~100-300 crystals) for benchmarking.\n",
    "\n",
    "The script will download matching cif files to the local machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import Block\n",
    "import pandas as pd\n",
    "import wget\n",
    "import openff\n",
    "import openbabel.pybel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Import allcod.smi and the sage-train set\n",
    "\n",
    "smiles = pd.read_csv('allcod.smi',names=['SMILES','COD ID'],sep='\\t')\n",
    "sage_train = pd.read_csv('sage-train-v1.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215       1010439\n",
      "359       1011023\n",
      "360       1011024\n",
      "374       1011063\n",
      "3375      1504357\n",
      "24122     2007371\n",
      "34268     2100348\n",
      "34269     2100349\n",
      "34270     2100350\n",
      "36279     2104943\n",
      "38092     2200599\n",
      "143548    4501702\n",
      "143549    4501703\n",
      "143550    4501704\n",
      "207528    9009215\n",
      "Name: COD ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make a list of SMILES from training set and prune duplicates\n",
    "training_smiles = sage_train['Component 1'].drop_duplicates().to_frame()\n",
    "training_smiles.rename(columns={'Component 1':'SMILES'},inplace=True)\n",
    "combined_set = smiles.merge(training_smiles,how='left',on='SMILES',indicator=True)\n",
    "matches = combined_set[combined_set['_merge'] == 'both']\n",
    "print(matches['COD ID'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openff' has no attribute 'evaluator'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_96798/613684211.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mqm_set\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopenff\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPhysicalPropertyDataSet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_json\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'2-0-0-td-set-v1.json'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mqm_set\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mqm_set\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'entries'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'https://api.qcarchive.molssi.org:443/'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mqm_smiles\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mqm_set\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mfoo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopenbabel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpybel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadstring\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'can'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'cmiles'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'openff' has no attribute 'evaluator'"
     ]
    }
   ],
   "source": [
    "qm_set = openff.evaluator.datasets.PhysicalPropertyDataSet.from_json('2-0-0-td-set-v1.json')\n",
    "qm_set = qm_set['entries']['https://api.qcarchive.molssi.org:443/']\n",
    "qm_smiles = []\n",
    "for i in qm_set:\n",
    "    foo = openbabel.pybel.readstring('can',i['cmiles'])\n",
    "    qm_smiles.append(foo.write('smi').strip())\n",
    "# Make a list of SMILES from qm set and prune duplicates\n",
    "qm_training_smiles = pd.DataFrame(qm_smiles,columns=['SMILES'])\n",
    "qm_combined_set = smiles.merge(qm_training_smiles,how='left',on='SMILES',indicator=True)\n",
    "qm_matches = qm_combined_set[qm_combined_set['_merge'] == 'both']\n",
    "print(qm_matches)\n",
    "all_matches = matches.append(qm_matches)\n",
    "print(all_matches['COD ID'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}